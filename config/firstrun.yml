IS_TEST: False

MODEL:
  TYPE: DeepLab

DATASET:
  ROOT: "/data"
  LIST_TRAIN: "config/dataset/lists/train.txt"
  LIST_VAL: "config/dataset/lists/val.txt"
  LIST_TEST: "config/dataset/lists/test.txt"
  INPUT:
    SENSOR: s2
    USED_CHANNELS: [1,2,3,4]
    STATS_FILE: "config/dataset/stats/channels_stats.json"
    CHANNELS: ["B1", "B2", "B3", "B4", "B5", "B6", "B7", "B8", "B8a", "B9", "B10", "B11", "B12"]
  MASK:
    SENSOR: lc
    CONFIG: "config/dataset/mask_configs/default.yml"
  CLASSES_COUNT_JSON: "config/dataset/stats/classes_count.json"
TRAIN:
  EPOCHS: 20
  RESUME_CHECKPOINT: ""
  BATCH_SIZE_PER_DEVICE: 16
  DEVICE: "cuda:2,3"
  WORKERS: 8
  SHUFFLE: True
  SEED: 42
  LOSS:
    TYPE: "categorical_crossentropy"
    USE_WEIGHTS: False
  OPTIMIZER: "adam"
  LR: 0.01
  WEIGHT_DECAY: 0.0001
  VERBOSE_STEP: 100
  VAL_PER_EPOCH: 6
  SCHEDULER:
    TYPE: "ReduceLROnPlateau"
    FACTOR: 0.2
    PATIENCE: 4
  WEIGHTS_FOLDER: "weights"
  USE_COMET: True
  COMET_TAGS: ["experiment"]
TEST:
  DEVICE: "cpu"
  WORKERS: 0
  BATCH_SIZE_PER_DEVICE: 1